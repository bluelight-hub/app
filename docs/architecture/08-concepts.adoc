= Übergreifende Konzepte
:author: Bluelight-Hub Team
:revnumber: 1.0.0
:revdate: 2025-03-23



== Übersicht
Dieser Abschnitt beschreibt übergreifende Konzepte und Prinzipien, die in der Architektur des Bluelight-Hub-Systems verankert sind. Diese Konzepte bilden die Grundlage für Entwurfsentscheidungen und erstrecken sich über mehrere Bausteine des Systems.

== Inhalt

=== Domänenmodell

Das Domänenmodell des Bluelight-Hub-Systems basiert auf dem "Einsatz" als zentraler Entität und den damit verbundenen Templates für wiederverwendbare Elemente. In der aktuellen Konzeption ist die Anwendung primär für die Verwaltung eines konkreten Einsatzes zuständig, wobei in den meisten Anwendungsfällen nicht mehr als ein Einsatz gleichzeitig aktiv ist.

Das grundlegende Konzept besteht darin, dass Templates für wiederverwendbare Elemente wie Personal, Fahrzeuge und Material existieren. Ein Einsatz wandelt diese Templates in konkrete Instanzen um und persistiert diese. Dadurch wird eine effiziente Erstellung und Verwaltung von Einsätzen ermöglicht, ohne jedes Mal alle Daten neu eingeben zu müssen.

[dbml]
....
// Einsatzverwaltung
Table einsatz {
  einsatzID varchar [primary key]
  bezeichnung varchar
  einsatzart_id varchar
  status varchar
  startzeit timestamp
  endzeit timestamp
}

Table einsatz_abschnitt {
  id varchar [primary key]
  einsatz_id varchar
  bezeichnung varchar
  verantwortlicher_id varchar
}

Table einsatz_art {
  code varchar [primary key]
  bezeichnung varchar
  prioritaet integer
}

// Templates
Table personal_template {
  id varchar [primary key]
  funktion varchar
  qualifikationen varchar
}

Table fahrzeug_template {
  id varchar [primary key]
  typ varchar
  kennzeichen varchar
  kapazitaet integer
}

Table material_template {
  id varchar [primary key]
  bezeichnung varchar
  kategorie varchar
}

// Ressourcenverwaltung
Table einheit {
  einheitID varchar [primary key]
  bezeichnung varchar
  typ varchar
  staerke integer
  status varchar
  einsatz_id varchar
  abschnitt_id varchar
}

Table personal {
  id varchar [primary key]
  template_id varchar
  name varchar
  status varchar
  einheit_id varchar
}

Table fahrzeug {
  id varchar [primary key]
  template_id varchar
  status varchar
  einheit_id varchar
}

Table fahrzeug_besatzung {
  fahrzeug_id varchar
  personal_id varchar
  
  indexes {
    (fahrzeug_id, personal_id) [pk]
  }
}

Table material {
  id varchar [primary key]
  template_id varchar
  anzahl integer
  status varchar
  einheit_id varchar
}

Table einsatzort {
  id varchar [primary key]
  einsatz_id varchar
  bezeichnung varchar
  lat float
  lng float
}

// Beziehungen
Ref: einsatz.einsatzart_id > einsatz_art.code
Ref: einsatz_abschnitt.einsatz_id > einsatz.einsatzID
Ref: einsatz_abschnitt.verantwortlicher_id > personal.id
Ref: einheit.einsatz_id > einsatz.einsatzID
Ref: einheit.abschnitt_id > einsatz_abschnitt.id
Ref: personal.template_id > personal_template.id
Ref: personal.einheit_id > einheit.einheitID
Ref: fahrzeug.template_id > fahrzeug_template.id
Ref: fahrzeug.einheit_id > einheit.einheitID
Ref: fahrzeug_besatzung.fahrzeug_id > fahrzeug.id
Ref: fahrzeug_besatzung.personal_id > personal.id
Ref: material.template_id > material_template.id
Ref: material.einheit_id > einheit.einheitID
Ref: einsatzort.einsatz_id > einsatz.einsatzID
....

==== Zentrale Entitäten

* *Einsatz*: Zentrale Entität, die einen konkreten Einsatzfall mit allen zugehörigen Informationen repräsentiert
* *EinsatzAbschnitt*: Unterbereich eines Einsatzes mit spezifischen Aufgaben und verantwortlichen Personen
* *Templates*: Wiederverwendbare Vorlagen für Personal, Fahrzeuge und Material
* *Instanzen*: Konkrete Ausprägungen von Templates im Kontext eines Einsatzes (Personal, Fahrzeuge, Material)
* *Einheit*: Organisatorische Einheit (z.B. Löschzug, Sanitätsgruppe), die Personal und Material umfasst

==== Beziehungen und Abhängigkeiten

* Ein Einsatz ist die zentrale Entität und kann in mehrere Einsatzabschnitte unterteilt werden
* Einsatzabschnitten können Einheiten zugeordnet werden
* Einem Einsatz sind mehrere Einheiten, Einsatzorte und eine Einsatzart zugeordnet
* Einheiten bestehen aus Personal, Fahrzeugen und Material
* Personal, Fahrzeuge und Material basieren auf Templates, die wiederverwendbare Informationen enthalten
* Bei Zuweisung zu einem Einsatz werden aus Templates konkrete Instanzen erstellt

==== Template-Konzept

Das Template-Konzept ist ein zentrales Merkmal des Domänenmodells:

* Templates dienen als wiederverwendbare Vorlagen für häufig genutzte Elemente
* Bei Einsatzerstellung werden aus Templates konkrete Instanzen erzeugt
* Änderungen an Templates wirken sich nicht rückwirkend auf bestehende Instanzen aus
* Templates ermöglichen die schnelle Konfiguration neuer Einsätze

=== Architektur- und Entwurfsmuster

==== Vereinfachte Schichtenarchitektur

Die Architektur folgt einem pragmatischen Schichtenmodell, das die Trennung von Zuständigkeiten gewährleistet, ohne unnötige Komplexität einzuführen. Statt einer vollständigen hexagonalen Architektur, die derzeit als zu komplex für die Anforderungen des Systems betrachtet wird, nutzt das System eine klare Trennung der Verantwortlichkeiten mit definierten Schichten.

[mermaid]
....
flowchart TD
    subgraph BluelightHub["Bluelight-Hub-System"]
        subgraph Praesentationsschicht["Präsentationsschicht"]
            UI["UI-Komponenten"]
            State["State Management"]
        end
        
        subgraph Anwendungsschicht["Anwendungsschicht"]
            Services["Services"]
            Controller["Controller"]
        end
        
        subgraph Datenhaltungsschicht["Datenhaltungsschicht"]
            Repositories["Repositories"]
            Datenmodelle["Datenmodelle"]
        end
    end
    
    UI --> State
    State --> Services
    Services --> Controller
    Controller --> Repositories
    Repositories --> Datenmodelle
    
    classDef presentation fill:#42A5F5,stroke:#1976D2,color:white
    classDef application fill:#66BB6A,stroke:#43A047,color:white
    classDef data fill:#FFA726,stroke:#FB8C00,color:white
    
    class UI,State presentation
    class Services,Controller application
    class Repositories,Datenmodelle data
    class Praesentationsschicht presentation
    class Anwendungsschicht application
    class Datenhaltungsschicht data
....

==== Optimierte Service-Struktur

Anstelle einer vollständigen CQRS-Implementierung, die für die aktuelle Anwendungsgröße und Komplexität als möglicherweise überdimensioniert betrachtet wird, verwendet das System eine optimierte Service-Struktur, die die Vorteile der Trennung von Lese- und Schreiboperationen bietet, ohne die Komplexität einer vollständigen CQRS-Architektur.

* *Services*: Kapseln die Geschäftslogik und Anwendungsfälle
* *Controller*: Bieten die REST-API-Schnittstellen nach außen
* *Repositories*: Abstrahieren den Datenzugriff und ermöglichen eine klare Trennung der Datenpersistenz

Diese vereinfachte Struktur ermöglicht:
* Einfachere Implementierung und Wartung
* Bessere Verständlichkeit für neue Entwickler
* Ausreichende Trennung der Zuständigkeiten
* Skalierbarkeit für die aktuelle Anwendungsgröße

==== Eventbasierte Kommunikation

Für die Kommunikation zwischen Modulen wird ein eventbasierter Ansatz verwendet:

* Klare Entkopplung der Komponenten
* Asynchrone Verarbeitung von Ereignissen
* Einfache Erweiterbarkeit durch neue Event-Handler
* Unterstützung des Verbindungskonzepts mit verschiedenen Konnektivitätsszenarien

=== Technische Konzepte

==== Verbindungskonzept

Das System ist in verschiedenen Konnektivitätsszenarien nutzbar:

* *Lokale Verbindung*: Der Client ist mit dem FüKW verbunden ("FüKW-verbunden")
* *Vollständige Verbindung*: Der FüKW ist mit dem Internet verbunden ("Online")
* *Autonomes Szenario*: Der Client hat keine Verbindung zum FüKW ("Offline")

Die aktuelle Implementierung fokussiert sich auf die ersten beiden Szenarien, wobei der lokale Verbindungsmodus die Verbindung zum FüKW beschreibt, nicht die vollständige Unabhängigkeit des Clients.

==== Testkonzept

Das Testkonzept des Bluelight-Hub-Systems adressiert die besonderen Herausforderungen einer Anwendung mit verschiedenen Verbindungsszenarien und hohen Anforderungen an Zuverlässigkeit und Benutzerfreundlichkeit.

===== Teststrategie für Verbindungsszenarien

Die Teststrategie berücksichtigt die drei Verbindungsszenarien:

* *Lokale Verbindung (FüKW-verbunden)*:
** Integration Tests für Client-FüKW-Kommunikation
** Simulation von Netzwerkbedingungen im lokalen Netzwerk
** Validierung der Datenübertragung und -synchronisation

* *Vollständige Verbindung (Online)*:
** End-to-End Tests mit externer Backend-Anbindung
** Lasttests für Skalierbarkeit und Performance
** Sicherheitstests für externe Schnittstellen

* *Autonomes Szenario (Offline)*:
** Unit Tests für lokale Datenverwaltung
** Simulation von Verbindungsabbrüchen und -wiederherstellungen
** Validierung der Datenintegritäts- und Konfliktlösungsmechanismen

===== Testbarkeit der Architektur

Die vereinfachte Schichtenarchitektur wurde mit Blick auf Testbarkeit entworfen:

* *Präsentationsschicht*:
** Komponententests für UI-Elemente
** Snapshot-Tests für visuelle Konsistenz
** Zustandstests für State Management

* *Anwendungsschicht*:
** Unit Tests für Services mit Mock-Repositories
** Integrationstests für Controller
** Verhaltensspezifikationstests für komplexe Geschäftslogik

* *Datenhaltungsschicht*:
** Unit Tests für Repository-Implementierungen
** Integrationstests mit In-Memory-Datenbank
** Persistenztests für Datenmigration und -integrität

===== Automatisierte Testprozesse

Das System nutzt mehrstufige automatisierte Testprozesse:

. *Kontinuierliche Integration*:
** Automatisierte Ausführung von Unit- und Integrationstests bei jedem Commit
** Statische Codeanalyse und Abdeckungsmessung
** Validierung der API-Kompatibilität

. *Release-Qualifikation*:
** Ausführung aller Testsuiten auf Produktionsumgebung
** Usability-Tests mit realen Nutzern
** Feldtests unter realistischen Einsatzbedingungen

===== Testdaten und -umgebungen

* *Testdaten*:
** Realistische Datensätze aus anonymisierten Einsatzszenarien
** Grenzfall-Testdaten für Extremsituationen
** Generierte Massendaten für Performancetests

===== Spezielle Testfokusgebiete

* *Synchronisationstests*:
** Validierung der Datensynchronisation zwischen Client und FüKW
** Behandlung von Konflikten bei gleichzeitigen Änderungen
** Wiederherstellung nach Verbindungsabbrüchen

* *Degradationstests*:
** Überprüfung der eingeschränkten Funktionalität bei Verbindungsverlust
** Validierung der Benutzerbenachrichtigungen und -führung
** Funktionsumfang in verschiedenen Verbindungsszenarien

* *Usability-Tests*:
** Benutzerfreundlichkeit in Stresssituationen
** Zugänglichkeit und Bedienbarkeit
** Effektivität unter realistischen Einsatzbedingungen

Diese umfassende Teststrategie stellt sicher, dass das Bluelight-Hub-System unter allen Einsatzbedingungen zuverlässig und effektiv funktioniert und die hohen Anforderungen an Qualität und Benutzerfreundlichkeit erfüllt.

==== Daten-Synchronisation

[mermaid]
....
sequenceDiagram
    participant Mobile as Mobile Client
    participant Server as FüKW-Server
    participant Other as Anderer Client

    Mobile->>Mobile: Lokale Änderung
    Mobile->>Mobile: Speichere Änderung + Timestamp
    
    alt Bei bestehender Verbindung
        Mobile->>Server: Sende Änderung
        Server->>Server: Validiere & Speichere
        Server->>Other: Propagiere Änderung
    else Bei Offline-Modus
        Mobile->>Mobile: Markiere zur Synchronisation
    end
    
    Note over Mobile,Server: Spätere Verbindungswiederherstellung
    
    Mobile->>Server: Sende ausstehende Änderungen
    Server->>Mobile: Sende verpasste Änderungen
    
    alt Bei Konflikt
        Server->>Server: Identifiziere Konflikt
        Server->>Mobile: Konfliktinformation
        Mobile->>Mobile: Zeige Konfliktlösung-UI
        Mobile->>Server: Sende aufgelösten Konflikt
    end
....

* Konfliktauflösung basierend auf Timestamps und Domänenregeln
* Selektive Synchronisation nach Priorität der Daten
* Bidirektionaler Synch-Mechanismus zwischen FüKW-Server und Mobilgeräten

==== Security-Konzept

* *Authentifizierung*: Rollenbasiertes Zugriffsmodell mit verschiedenen Berechtigungsstufen
* *Datenschutz*: Verschlüsselung sensibler Daten in Rest und während der Übertragung
* *Auditierung*: Logging aller sicherheitsrelevanten Ereignisse für spätere Analyse

==== Fehlerbehandlung und Resilience

* Graceful Degradation bei Teilausfällen
* Circuit Breaker Pattern für externe Integrationen
* Automatische Wiederherstellung nach Systemfehlern

=== UI-Konzepte

==== Responsive Design

* Adaptives Layout für verschiedene Bildschirmgrößen
* Touch-optimierte Bedienung für Tablet-Nutzung im Einsatz
* Barrierefreiheit für verschiedene Nutzergruppen

==== Dashboard-Ansichten

Das Bluelight-Hub-System nutzt spezialisierte Dashboard-Ansichten für die Visualisierung und das Monitoring wichtiger Einsatzdaten:

* Separate Webview-Fenster für fokussierte Darstellung
* Optimiert für Multi-Monitor-Setups im Einsatzumfeld
* Automatische Datenaktualisierung mit konfigurierbaren Intervallen
* Statistische Übersichten und detaillierte Echtzeit-Informationen
* Klare visuelle Hierarchie für schnelle Informationserfassung

[mermaid]
....
flowchart TD
    MainApp[Hauptanwendung] --> |öffnet| WebView[Dashboard Webview]
    WebView --> |zeigt| DashboardLayout[Dashboard Layout]
    DashboardLayout --> |enthält| Stats[Statistiken]
    DashboardLayout --> |enthält| Tables[Tabellen/Listen]
    DashboardLayout --> |enthält| RefreshMech[Aktualisierungsmechanismus]
    
    classDef main fill:#42A5F5,stroke:#1976D2,color:white
    classDef view fill:#66BB6A,stroke:#43A047,color:white
    classDef comp fill:#FFA726,stroke:#FB8C00,color:white
    
    class MainApp main
    class WebView,DashboardLayout view
    class Stats,Tables,RefreshMech comp
....

Die Dashboard-Architektur nutzt Tauri Webviews für leichtgewichtige, separate Fenster, die dennoch eng mit der Hauptanwendung integriert sind. Die vollständige Begründung und technische Details sind in <<../adr/009-dashboard-architektur.adoc>> dokumentiert.

==== Kontextbezogene Benutzeroberfläche

* Anpassung der UI basierend auf Einsatzrolle und -phase
* Priorisierung relevanter Informationen im aktuellen Kontext
* Reduktion kognitiver Belastung durch fokussierte Ansichten

=== Persistenzkonzept

* PostgreSQL als Datenbank
* Versionierung von Datensätzen für Konfliktauflösung
* Inkrementelle Backups auf FüKW-Server

=== Integrations- und Schnittstellenkonzept

* RESTful APIs für synchrone Kommunikation
* WebSockets für Echtzeitkommunikation
* Standardisierte Schnittstellen zu Leitstellen-Systemen
* Adapter für Digitalfunk-Integration

=== NestJS Backend-Architekturkonzepte

==== Übersicht und Prinzipien

Das Backend des Bluelight-Hub-Systems basiert auf dem NestJS-Framework und folgt der modularen Architektur, die dieses Framework vorgibt. NestJS wurde gewählt, da es eine strukturierte, modulare und gut skalierbare Codebasis ermöglicht, die auf bewährten Konzepten wie Dependency Injection, AOP (Aspect-Oriented Programming) und dem SOLID-Prinzip basiert.

Die Hauptprinzipien unserer Backend-Architektur sind:

1. **Domänenorientierte Modularisierung**: Organisation des Codes nach Geschäftsdomänen statt nach technischen Aspekten
2. **Klare Schichtenarchitektur**: Trennung von Kontrollebene (Controller), Geschäftslogik (Services) und Datenzugriff (Repositories)
3. **Dependency Injection**: Verwendung des integrieren DI-Containers für lose Kopplung und verbesserte Testbarkeit
4. **Consistent Error Handling**: Einheitliche Fehlerbehandlung durch Exception Filter
5. **Typed Interfaces**: Konsequente Nutzung von TypeScript für Typsicherheit auf allen Ebenen
6. **Cross-Cutting Concerns Separation**: Aspekte wie Logging, Validierung und Auth in spezialisierten Komponenten

==== Modulare Struktur

Die Backend-Codebasis ist in `packages/backend` organisiert und folgt dieser grundlegenden Struktur:

[source]
----
packages/backend/
├── common/           # Querschnittskomponenten
│   ├── decorators/   # Custom-Decorators
│   ├── filters/      # Exception Filter
│   ├── guards/       # Auth Guards
│   ├── interceptors/ # Interceptors
│   └── pipes/        # Validierungs-Pipes
├── config/           # Konfigurationen
└── modules/          # Fachliche Module
    ├── auth/         # Authentifizierungsmodul
    ├── einsatz/      # Einsatzmodul
    └── ...           # Weitere Fachmodule
----

Jedes Fachmodul ist nach dieser Struktur organisiert:

[source]
----
modules/module-name/
├── controllers/      # API-Endpoints
├── services/         # Geschäftslogik
├── repositories/     # Datenzugriff
├── entities/         # Datenbankmodelle
├── dto/              # Data Transfer Objects
├── interfaces/       # TypeScript-Interfaces
├── enums/            # Enumerationen
├── constants/        # Konstanten
├── utils/            # Hilfsfunktionen
└── __tests__/        # Tests
----

==== Architekturmuster und Pattern

===== Domain-Driven Design (DDD)

Die Backend-Architektur orientiert sich an DDD-Prinzipien:

* **Bounded Contexts**: Module repräsentieren abgegrenzte Fachdomänen
* **Entities**: Objekte mit Identität über ihren Lebenszyklus
* **Value Objects**: Unveränderliche Objekte ohne eigene Identität
* **Domain Services**: Komplexe Geschäftslogik, die nicht zu einer einzelnen Entität gehört
* **Repositories**: Abstraktion des Datenzugriffs

===== CQRS-Grundsätze

Für komplexere Domänen kann das CQRS-Muster (Command Query Responsibility Segregation) angewendet werden:

* **Queries**: Leseoperationen werden in spezialisierten Query-Handlern implementiert
* **Commands**: Schreiboperationen werden in Command-Handlern gekapselt
* **Events**: Domänen-Events signalisieren wichtige Änderungen

===== Repository Pattern

Das Repository-Pattern abstrahiert den Datenbankzugriff:

* **Einheitliche Schnittstelle**: Konsistente Methoden für alle Entitäten
* **Testbarkeit**: Repositories können leicht gemockt werden
* **Separation of Concerns**: Trennung von Datenzugriff und Geschäftslogik
* **Typsicherheit**: Prisma-Integration mit vollständiger TypeScript-Unterstützung und generierten Typen

===== Prisma ORM

Der Datenbankzugriff erfolgt über Prisma ORM, das folgende Vorteile bietet:

* **Typsicherheit**: Generierte Typen für alle Abfragen und Modelle
* **Intuitive Abfrage-API**: Fluent API für einfache und komplexe Abfragen
* **Migrationssystem**: Robustes und versioniertes Migrationssystem
* **Schema-first Ansatz**: Klare und zentrale Definition des Datenbankschemas
* **Transaktionen**: First-class Support für atomare Transaktionen
* **Optimierte Abfragen**: Effiziente SQL-Abfragen ohne N+1 Probleme

Die Integration erfolgt über den `PrismaService`, der als globaler Provider in der Anwendung verfügbar ist und den Prisma Client bereitstellt.

```typescript
@Injectable()
export class PrismaService extends PrismaClient implements OnModuleInit, OnModuleDestroy {
  async onModuleInit() {
    await this.$connect();
  }

  async onModuleDestroy() {
    await this.$disconnect();
  }
}
```

Das Prisma-Schema in `schema.prisma` definiert alle Modelle und ihre Beziehungen und dient als zentrale Wahrheit für die Datenbankstruktur.

===== Dependency Injection

NestJS bietet einen leistungsfähigen DI-Container:

* **Constructor Injection**: Dependencies werden im Konstruktor injiziert
* **Provider System**: Services, Repositories und andere Komponenten als Provider
* **Scopes**: Singleton (Standard), Request-scoped oder Transient Instanzen
* **Custom Providers**: Factory-Provider für komplexe Instanziierung

==== Komponententypen

Die Backend-Architektur umfasst folgende Hauptkomponententypen:

[cols="1,3,2", options="header"]
|===
|Komponente |Verantwortlichkeit |Pattern/Prinzip
|Controller |Definieren der HTTP-Endpunkte und Routing |MVC Controller
|Service |Implementierung der Geschäftslogik |Domain Service
|Repository |Datenbankoperationen und Abfragen |Repository Pattern
|Entity |Datenbankmodelle und Beziehungen |Domain Entity
|DTO |Datenstrukturen für API-Kommunikation |Data Transfer Object
|Module |Komponenten-Bündelung und -Organisation |Modul Pattern
|Guard |Zugriffskontrolle und Autorisierung |Intercepting Filter
|Interceptor |Request/Response-Transformation |AOP/Decorator
|Pipe |Eingabevalidierung und -transformation |Filter/Interceptor
|Filter |Fehlerbehandlung und -formatierung |Exception Handler
|Decorator |Metaprogrammierung und Annotationen |Decorator Pattern
|===

==== Architekturentscheidungen

Bei der Entwicklung des Backends wurden folgende Architekturentscheidungen getroffen:

1. **Monolithische Struktur mit modularer Organisation**: Trotz der Unterteilung in Module wird das Backend als Monolith deployed, aber mit klarer Trennung zwischen den Modulen für mögliche spätere Extraktion.

2. **Shared Types mit Frontend**: DTOs und Entitäten werden durch OpenAPI/Swagger-Generierung mit dem Frontend geteilt, um Typkonsistenz zu gewährleisten.

3. **PostgreSQL als Primärdatenbank**: Verwendung von PostgreSQL für Robustheit, Skalierbarkeit und erweiterte Funktionen.

4. **Repository Pattern über Active Record**: Bewusste Entscheidung für das Repository-Pattern statt Active Record für bessere Testbarkeit und Abstraktion.

5. **Einheitliche Fehlerbehandlung**: Globale Exception Filter für konsistente API-Fehlerantworten.

==== API-Design

Das API-Design folgt den REST-Prinzipien mit folgenden Merkmalen:

* **Ressourcenorientiert**: Endpunkte repräsentieren Ressourcen, nicht Aktionen
* **HTTP-Verben**: Verwendung von GET, POST, PUT, DELETE für CRUD-Operationen
* **Versionierung**: API-Versionen durch URI-Pfad (/api/v1/resource)
* **Dokumentation**: OpenAPI/Swagger-Dokumentation für alle Endpunkte
* **Validierung**: DTO-basierte Eingabevalidierung mit class-validator
* **Fehlerformate**: Einheitliches Fehlerformat mit HTTP-Statuscodes

==== Standardisierte API-Antwortstruktur

Eine der wichtigsten Architekturentscheidungen im Backend ist die Verwendung einer standardisierten API-Antwortstruktur. Diese gewährleistet ein konsistentes Format für alle API-Antworten und verbessert die Nutzererfahrung, Wartbarkeit und Testbarkeit.

===== ApiResponse<T> Basisklasse

Das Herzstück des API-Antwortkonzepts ist die abstrakte Klasse `ApiResponse<T>`:

[source,typescript]
----
export abstract class ApiResponse<T> {
    abstract data: T;
    meta: ApiMeta;
    message?: string;
}

export class ApiMeta {
    timestamp: string;
}
----

Diese Struktur stellt sicher, dass jede API-Antwort folgendes enthält:
* **data**: Die eigentlichen Antwortdaten mit spezifischem Typ
* **meta**: Metadaten wie Zeitstempel oder Paginierungsinformationen
* **message**: Optionale Nachricht für zusätzliche Informationen

===== Integration mit TransformInterceptor

Die standardisierte Antwortstruktur wird durch einen `TransformInterceptor` automatisiert, der jeden Controller-Rückgabewert in das definierte Format umwandelt. Dies vereinfacht die Controller-Implementierung und stellt gleichzeitig Konsistenz sicher.

Der Interceptor kann auf Controller- oder Routenebene angewendet werden:

[source,typescript]
----
@Controller('beispiel')
@UseInterceptors(TransformInterceptor)
export class BeispielController {
    // Kontroller-Methoden geben direkt ihre Daten zurück
    // Der Interceptor wandelt sie automatisch in ApiResponse<T> um
}
----

===== Konkrete Response-DTOs

Für verschiedene Anwendungsfälle werden spezialisierte Response-DTOs erstellt, die von `ApiResponse<T>` ableiten:

* **Einzelobjekt-Antworten**:
[source,typescript]
----
export class EntityResponse extends ApiResponse<EntityDto> {
    @ApiProperty({ type: EntityDto })
    data: EntityDto;
}
----

* **Listen-Antworten**:
[source,typescript]
----
export class EntitiesResponse extends ApiResponse<EntityDto[]> {
    @ApiProperty({ 
        type: EntityDto,
        isArray: true
    })
    data: EntityDto[];
}
----

* **Paginierte Antworten**:
[source,typescript]
----
export class PaginatedResponse<T> {
    @ApiProperty({ isArray: true })
    items: T[];
    
    @ApiProperty({ type: PaginationMeta })
    pagination: PaginationMeta;
}

export class PaginatedEntitiesResponse extends ApiResponse<PaginatedResponse<EntityDto>> {
    @ApiProperty({ type: () => PaginatedResponse })
    data: PaginatedResponse<EntityDto>;
}
----

===== Vorteile der standardisierten Antwortstruktur

Die einheitliche API-Antwortstruktur bietet mehrere Vorteile:

1. **Konsistenz**: Alle API-Antworten folgen demselben Muster, was die Client-Integration vereinfacht
2. **Metadaten**: Zusätzliche Informationen können konsistent übermittelt werden
3. **Erweiterbarkeit**: Neue Metadatenfelder können hinzugefügt werden, ohne bestehende Clients zu beeinträchtigen
4. **Dokumentation**: Durch Swagger/OpenAPI-Integration ist die Struktur gut dokumentiert
5. **Fehlerbehandlung**: Konsistentes Format auch für Fehlerantworten möglich
6. **Testbarkeit**: Einheitliche Struktur vereinfacht das Testen von API-Antworten

===== Integration mit Frontend

Das Frontend kann sich auf diese konsistente Struktur verlassen und generische Komponenten für das Handling von API-Antworten implementieren. Die OpenAPI-generierte Client-Bibliothek spiegelt diese Struktur im Frontend wider.

==== Standardisierte Validierungs-Dekoratoren

Das Backend des Bluelight-Hub-Systems verwendet eine Reihe standardisierter Validierungs-Dekoratoren, um die Gültigkeit von Eingabedaten sicherzustellen. Neben den von class-validator bereitgestellten Standard-Dekoratoren wurden verschiedene benutzerdefinierte Validierungs-Dekoratoren entwickelt, um projektspezifische Validierungsanforderungen zu erfüllen.

===== IsNanoId Validator

Die `IsNanoId`-Validierung ist ein benutzerdefinierter Decorator, der die Gültigkeit von NanoID-Strings überprüft. NanoIDs werden im System als ID-Format für verschiedene Entitäten verwendet und bieten eine Alternative zu UUIDs mit kürzeren, URL-freundlichen IDs.

*Implementierung:*

[source,typescript]
----
@IsNanoId()
@IsOptional()
referenzPatientId?: string;
----

Der `IsNanoId`-Validator prüft folgende Kriterien:

1. Der Wert muss ein String sein
2. Der String muss die korrekte Länge haben (standardmäßig 21 Zeichen, kann aber konfiguriert werden)
3. Der String darf nur Zeichen aus dem NanoID-Alphabet enthalten (A-Za-z0-9_-)

*Konfiguration:*

[source,typescript]
----
// Standard-Verwendung (21 Zeichen)
@IsNanoId()
id: string;

// Angepasste Länge (z.B. 10 Zeichen)
@IsNanoId({}, 10)
kurzId: string;
----

Diese Validierungen gewährleisten, dass alle in das System eingehenden IDs dem erwarteten Format entsprechen, wodurch Fehler bei Datenbankabfragen und -operationen vermieden werden.

==== Querschnittskonzepte

Folgende Querschnittskonzepte ziehen sich durch die gesamte Backend-Architektur:

* **Logging**: Strukturiertes Logging mit dem consola-Logger

===== Logging-Konzept

Das Bluelight-Hub-System setzt auf ein strukturiertes Logging-Konzept, das auf der consola-Bibliothek basiert. Dies bietet mehrere Vorteile gegenüber der direkten Verwendung von console.log:

[source]
----
// Importieren des Loggers
import { logger } from '@/logger/consola.logger';

// Verschiedene Log-Level verwenden
logger.info('Informative Nachricht');
logger.error('Fehlermeldung', errorObject);
logger.warn('Warnung');
logger.debug('Debug-Information');
logger.trace('Detaillierte Trace-Information');
----

*Hauptmerkmale des Logging-Konzepts:*

1. **Zentrale Logger-Implementation**: `packages/backend/src/logger/consola.logger.ts` stellt einen einheitlichen Logger bereit:
   * Als direkt importierbarer `logger`
   * Als `ConsolaLogger`-Klasse für die NestJS LoggerService-Integration

2. **Umgebungsabhängige Log-Level-Konfiguration**:
   * Produktion: Log-Level 3 (info) - Nur wichtige Nachrichten
   * Entwicklung: Log-Level 4 (debug) - Detailliertere Informationen

3. **Architekturelle Vorgaben**:
   * Verwendung von `console.*` ist nicht erlaubt und wird durch Architekturtests verhindert
   * Einheitliche Logger-Integration für konsistente Ausgabeformate

4. **Verfügbare Log-Level**:
   * `error`: Kritische Fehler, die Aufmerksamkeit erfordern
   * `warn`: Warnungen über potenzielle Probleme
   * `info`: Allgemeine Informationen zum Programmablauf
   * `debug`: Ausführliche Informationen für Entwickler
   * `trace`: Detaillierte Nachverfolgung für tiefergehende Analyse

5. **Integration mit NestJS**:
   * Bereitstellung als Provider in der Anwendung: `{ provide: 'Logger', useClass: ConsolaLogger }`
   * Konsistente Verwendung in allen Modulen durch Dependency Injection

*Vorteile des strukturierten Loggings:*

* **Konsistenz**: Einheitliches Format und Log-Level-Steuerung
* **Filterbarkeit**: Nachrichten können nach Level gefiltert werden
* **Formatierung**: Bessere Lesbarkeit als direkte Console-Ausgaben
* **Konfigurierbarkeit**: Anpassbare Log-Level je nach Umgebung
* **Erweiterbarkeit**: Möglichkeit zur Integration mit externen Logging-Diensten

*Code-Beispiel für die Verwendung in NestJS-Komponenten:*

[source,typescript]
----
import { Injectable } from '@nestjs/common';
import { logger } from '@/logger/consola.logger';

@Injectable()
export class UserService {
    async findUser(id: string) {
        logger.debug(`Suche nach Benutzer mit ID: ${id}`);
        
        try {
            // Geschäftslogik
            
            logger.info(`Benutzer ${id} erfolgreich gefunden`);
            return user;
        } catch (error) {
            logger.error(`Fehler beim Suchen des Benutzers ${id}:`, error);
            throw error;
        }
    }
}
----

*Architektursicherung:*

Um sicherzustellen, dass die Logger-Konvention eingehalten wird, verfügt das System über einen speziellen Architekturtest (`logger.architecture.spec.ts`), der den gesamten Codebase auf direkte Verwendung von `console.*`-Aufrufen prüft und den Test fehlschlagen lässt, wenn solche gefunden werden.

* **Authentifizierung**: JWT-basierte Authentifizierung mit Guards

Diese Architekturkonzepte bilden das Fundament für ein wartbares, erweiterbares und robustes Backend-System, das kontinuierlich weiterentwickelt werden kann.

== Offene Punkte und Entscheidungen

* Detaillierte Spezifikation der Konfliktlösungsstrategien bei Daten-Synchronisation
* Definition von Performance-Benchmarks für Offline-Operationen
* Auswahl spezifischer Verschlüsselungsstandards für sensible Daten

[mermaid]
....
flowchart TD
    ConnectionCheck{Verbindung?}
    ConnectionCheck -->|Verbunden zum FüKW| LOCAL[Lokale Verbindung]
    ConnectionCheck -->|Keine Verbindung| OFFLINE[Autonomer Offline-Modus]
    LOCAL --> InternetCheck{Internet verfügbar?}
    InternetCheck -->|Ja| ONLINE[Online-Modus mit erweiterten Funktionen]
    InternetCheck -->|Nein| LOCALONLY[Nur lokale FüKW-Funktionalität]
....

[mermaid]
....
graph TD
    A[Client App] --> B{Verbindungszustand?}
    B -->|FüKW-verbunden| C[Lokale Verbindung]
    B -->|Online| D[Vollständige Verbindung]
    B -->|Offline| E[Autonomer Modus]
    
    C --> F[Vollständige lokale Funktionalität]
    D --> G[Erweiterte Funktionen]
    E --> H[Eingeschränkte Funktionalität]
    
    C -.-> I[Synchronisation nur mit lokalen Clients]
    D -.-> J[Volle Synchronisation]
    E -.-> K[Lokales Speichern, spätere Sync]
    
    style C fill:#B3E5FC,stroke:#0288D1
    style D fill:#BBDEFB,stroke:#1976D2
    style E fill:#FFECB3,stroke:#FF8C00
....

=== Seeding- und Profile-System

Das Seeding- und Profile-System ist ein spezialisiertes Subsystem für die Erstellung und Verwaltung von Test- und Entwicklungsdaten. Es ermöglicht die schnelle Generierung realistischer DRK-Einsatzszenarien für Entwicklung, Testing und Demonstrations-zwecke.

==== Konzept und Motivation

Das System adressiert die Herausforderung, dass Entwickler und Tester konsistente, realistische Daten für ihre Arbeit benötigen, ohne jedes Mal manuell komplexe Einsatzszenarien erstellen zu müssen.

*Hauptziele:*
* Standardisierte, wiederverwendbare Einsatzszenarien für das DRK
* Reduzierte Einrichtungszeit für Entwicklungs- und Testumgebungen
* Konsistente Testdaten für reproduzierbare Tests
* Realistische Demo-Daten für Präsentationen und Schulungen

==== Architektur des Profile-Systems

[mermaid]
....
flowchart TD
    ProfileConfig[Profile-Konfiguration] --> ProfileService[ProfileService]
    ProfileService --> SeedService[SeedService]
    SeedService --> EinsatzService[EinsatzService]
    EinsatzService --> Database[(Datenbank)]
    
    CLI[CLI Interface] --> ProfileService
    AdminPanel[Admin Panel] --> ProfileService
    DevSeedService[DevSeedService] --> ProfileService
    
    ProfileConfig --> |definiert| DRKProfiles[DRK-Profile]
    DRKProfiles --> |MANV| MANVProfile[MANV-Szenario]
    DRKProfiles --> |Sanitätsdienst| SaniProfile[Sanitätsdienst-Szenario]
    DRKProfiles --> |KatS| KatSProfile[Katastrophenschutz]
    DRKProfiles --> |weitere| OtherProfiles[...]
    
    classDef config fill:#FFE082,stroke:#FFC107,color:black
    classDef service fill:#81C784,stroke:#4CAF50,color:white
    classDef interface fill:#64B5F6,stroke:#2196F3,color:white
    classDef data fill:#FFAB91,stroke:#FF5722,color:white
    
    class ProfileConfig,DRKProfiles,MANVProfile,SaniProfile,KatSProfile,OtherProfiles config
    class ProfileService,SeedService,EinsatzService,DevSeedService service
    class CLI,AdminPanel interface
    class Database data
....

==== Profile-Struktur und Metadaten

Profile enthalten sowohl die eigentlichen Einsatzdaten als auch umfangreiche Metadaten für die Kategorisierung und Verwendung:

[source,typescript]
----
interface SeedProfile {
  key: string;                    // Eindeutiger Identifikator
  name: string;                   // Anzeigename
  description: string;            // Ausführliche Beschreibung
  einsatz: {
    name: string;                 // Einsatzname
    beschreibung: string;         // Detaillierte Szenario-Beschreibung
  };
  metadata: {
    category: DRKEinsatzCategory; // Kategorisierung
    estimatedPersonsAffected: number;
    estimatedDurationHours: number;
    requiredResources: string[];  // Benötigte Ressourcen
    priority: 'low' | 'medium' | 'high' | 'critical';
  };
}
----

==== DRK-spezifische Profile-Kategorien

Das System bietet vordefinierte Profile für typische DRK-Einsatzbereiche:

* *MANV (Massenanfall von Verletzten)*: Großschadensereignisse mit vielen Verletzten
* *Sanitätsdienst*: Medizinische Betreuung bei Veranstaltungen  
* *Katastrophenschutz*: Naturkatastrophen und Großschadensereignisse
* *Betreuung*: Soziale Betreuung und Versorgung von Evakuierten
* *Rettungsdienst*: Reguläre medizinische Notfallversorgung
* *PSNV*: Psychosoziale Notfallversorgung
* *Ausbildung*: Simulierte Einsätze für Übungszwecke

==== Verwendungsszenarien

===== Entwicklungsumgebung
* Automatische Initialisierung mit Standard-Einsatz beim App-Start
* Schnelle Erstellung verschiedener Testszenarien
* Konsistente Ausgangslage für Feature-Entwicklung

===== Testing
* Reproduzierbare Testdaten für Unit- und Integrationstests
* Stress-Testing mit verschiedenen Einsatzgrößen
* Grenzfall-Tests mit komplexen Szenarien

===== Präsentationen und Demos
* Realistische Daten für Stakeholder-Präsentationen
* Verschiedene Einsatztypen für Feature-Demonstrationen
* Schneller Wechsel zwischen Szenarien

==== Schnittstellen und Zugriffsmethoden

===== CLI-Interface
Das Command-Line-Interface bietet direkten Zugriff für Entwickler:

[source,bash]
----
# Profile auflisten
npm run cli seed:einsatz --list

# Detaillierte Profilinformationen
npm run cli seed:einsatz --info manv

# Einsatz aus Profil erstellen  
npm run cli seed:einsatz --profile manv

# Nach Kategorie filtern
npm run cli seed:einsatz --category katastrophenschutz
----

===== Admin-Panel-Integration (geplant)
Web-basierte Oberfläche für erweiterte Profile-Verwaltung:
* Visual Profile-Browser mit Filterung und Suche
* Bulk-Operations für mehrere Profile
* Custom-Profile-Editor für projektspezifische Szenarien
* Import/Export von Profile-Sets

===== Programmatische API
Direkte Integration in Backend-Services:

[source,typescript]
----
// Einsatz aus Profil erstellen
const einsatz = await profileService.createEinsatzFromProfile('manv');

// Profile nach Kriterien suchen
const criticalProfiles = profileService.getProfilesByPriority('critical');

// Custom-Empfehlungen
const recommended = profileService.getRecommendedProfiles({
  maxPersonsAffected: 50,
  maxDurationHours: 12
});
----

==== Error Handling und Race Condition Prevention

Das Seeding-System nutzt erweiterte Fehlerbehandlung für robuste Operation in verschiedenen Umgebungen:

* *Retry-Mechanismus*: Exponential Backoff für transiente Fehler
* *Duplicate Detection*: Verhindert doppelte Einsätze bei parallelen Operationen  
* *Umgebungsspezifisches Verhalten*: Angepasste Strategien für Dev/Test/Prod
* *PostgreSQL-spezifische Optimierungen*: Nutzt DB-Features für Konsistenz

==== Erweiterbarkeit und Anpassung

===== Custom-Profile
* Projektspezifische Profile zusätzlich zu Standard-DRK-Profilen
* Template-basierte Profile-Erstellung
* Versionierung und Migration von Profilen

===== Plugin-Architektur
* Erweiterbare Profile-Generatoren
* Custom-Metadata-Provider
* Integration mit externen Datenquellen

===== Konfigurierbarkeit
* Umgebungsabhängige Profile-Sets
* Konfigurierbare Default-Profile
* Feature-Flags für verschiedene Profile-Features

==== Security und Compliance

* *Zugriffskontrolle*: Profile-basierte Berechtigungen je nach Umgebung
* *Audit-Logging*: Vollständige Nachverfolgung von Seeding-Operationen
* *Datenschutz*: Anonymisierte/synthetische Daten in Profilen
* *Umgebungsisolation*: Strikte Trennung zwischen Dev-, Test- und Prod-Profilen

Dieses System stellt sicher, dass realistische und konsistente Testdaten für alle Entwicklungs- und Testaktivitäten verfügbar sind, während gleichzeitig die Sicherheits- und Compliance-Anforderungen des DRK-Umfelds erfüllt werden.